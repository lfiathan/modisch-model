{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1654,
     "status": "ok",
     "timestamp": 1760409026274,
     "user": {
      "displayName": "alif aditya",
      "userId": "09765680414298989716"
     },
     "user_tz": -420
    },
    "id": "kMi2042vPb_X",
    "outputId": "edcc49a4-d6bf-4af9-ee54-f7fa0b9d4c46"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import kaggle\n",
    "import yaml\n",
    "import pathlib\n",
    "import random\n",
    "import shutil\n",
    "import torch\n",
    "import sys\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#test pr\n",
    "# Notebook can't use relative package imports; ensure src is on sys.path and import absolutely.\n",
    "sys.path.append(str(pathlib.Path('..').resolve() / 'src'))\n",
    "from modeling.common import switch_labels\n",
    "\n",
    "print('Data source import complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gAXwA1GPb_Y"
   },
   "source": [
    "# YOLOv8\n",
    "YOLOv8 is the newest state-of-the-art YOLO model that can be used for object detection, image classification, and instance segmentation tasks.<br>\n",
    "YOLOv8 includes numerous architectural and developer experience changes and improvements over YOLOv5.<br>\n",
    "\n",
    "## Why Should I Use YOLOv8?\n",
    "* YOLOv8 has a high rate of accuracy measured by COCO and Roboflow 100.\n",
    "* YOLOv8 comes with a lot of developer-convenience features, from an easy-to-use CLI to a well-structured Python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths (match your notebook variables)\n",
    "output_path = '../dataset'\n",
    "dataset_root = os.path.join(output_path, 'colorful_fashion_dataset_for_object_detection')\n",
    "jpeg_dir = os.path.join(dataset_root, 'JPEGImages')\n",
    "images_alias = os.path.join(dataset_root, 'images')  # YOLO-friendly\n",
    "labels_dir = os.path.join(dataset_root, 'labels')    # where your phase labels are moved before training\n",
    "original_annotations_path = os.path.join(dataset_root, 'Annotations_txt')\n",
    "\n",
    "# 1) Make 'images' alias -> JPEGImages\n",
    "if not os.path.exists(images_alias):\n",
    "    try:\n",
    "        os.symlink(os.path.relpath(jpeg_dir, dataset_root), images_alias)\n",
    "        print(f\"âœ… Symlink created: {images_alias} -> {jpeg_dir}\")\n",
    "    except Exception as e:\n",
    "        # Fallback: duplicate folder name (uses extra space)\n",
    "        if not os.path.exists(images_alias):\n",
    "            shutil.copytree(jpeg_dir, images_alias)\n",
    "            print(f\"âœ… Copied images to: {images_alias}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Move phase labels to 'labels' directory\n",
    "def move_dir_overwrite(src, dst):\n",
    "    if not os.path.exists(src):\n",
    "        print(f\"Skip move: missing {src}\")\n",
    "        return\n",
    "    if os.path.exists(dst):\n",
    "        # avoid rmtree if they are the same inode\n",
    "        try:\n",
    "            if os.path.samefile(src, dst):\n",
    "                return\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        shutil.rmtree(dst)\n",
    "    shutil.move(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Regenerate train/val lists that point to the 'images' alias\n",
    "def resolve_image_path(img_name, images_dir):\n",
    "    img_name = img_name.strip()\n",
    "    if not img_name:\n",
    "        return None\n",
    "    exts = ('.jpg', '.jpeg', '.png', '.JPG', '.PNG')\n",
    "    cands = [img_name] if os.path.splitext(img_name)[1] else [img_name + ext for ext in exts]\n",
    "    for c in cands:\n",
    "        p = os.path.join(images_dir, c)\n",
    "        if os.path.exists(p):\n",
    "            return os.path.abspath(p)\n",
    "    base = os.path.splitext(img_name)[0]\n",
    "    for f in os.listdir(images_dir):\n",
    "        if os.path.splitext(f)[0] == base:\n",
    "            return os.path.abspath(os.path.join(images_dir, f))\n",
    "    return None\n",
    "\n",
    "def make_list_from_imagesets(images_dir, list_relpath, out_txt):\n",
    "    list_path = os.path.join(dataset_root, list_relpath)\n",
    "    lines = []\n",
    "    if os.path.exists(list_path):\n",
    "        with open(list_path, 'r') as f:\n",
    "            for l in f:\n",
    "                p = resolve_image_path(l, images_dir)\n",
    "                if p:\n",
    "                    lines.append(p)\n",
    "    else:\n",
    "        print(f\"âš ï¸ Missing: {list_path}\")\n",
    "    with open(out_txt, 'w') as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "    print(f\"âœ… Wrote {out_txt} with {len(lines)} entries\")\n",
    "\n",
    "train_list_txt = os.path.abspath(os.path.join(dataset_root, 'train_full.txt'))\n",
    "val_list_txt   = os.path.abspath(os.path.join(dataset_root, 'val_full.txt'))\n",
    "\n",
    "make_list_from_imagesets(images_alias, 'ImageSets/Main/trainval.txt', train_list_txt)\n",
    "make_list_from_imagesets(images_alias, 'ImageSets/Main/test.txt',     val_list_txt)\n",
    "\n",
    "# 3) Rewrite YAMLs to reference these lists\n",
    "def write_phase_yaml(path_root, train_txt, val_txt, names, out_fname):\n",
    "    cfg = {\n",
    "        'path': os.path.abspath(path_root),\n",
    "        'train': os.path.abspath(train_txt),\n",
    "        'val': os.path.abspath(val_txt),\n",
    "        'names': {i: n for i, n in enumerate(names)},\n",
    "    }\n",
    "    with open(out_fname, 'w') as f:\n",
    "        yaml.dump(cfg, f, sort_keys=False)\n",
    "    print(f\"âœ… Wrote {out_fname}\")\n",
    "\n",
    "phase1_names = ['TOP','BOTTOM','SHOES']\n",
    "phase2_names = ['jacket','shirt','pants','shorts','skirt','dress','shoe']\n",
    "\n",
    "write_phase_yaml(dataset_root, train_list_txt, val_list_txt, phase1_names, 'phase1-data.yaml')\n",
    "write_phase_yaml(dataset_root, train_list_txt, val_list_txt, phase2_names, 'phase2-data.yaml')\n",
    "\n",
    "# 4) Clear stale caches so YOLO reindexes with labels\n",
    "for cache_name in ('JPEGImages.cache', 'images.cache'):\n",
    "    cp = os.path.join(dataset_root, cache_name)\n",
    "    if os.path.exists(cp):\n",
    "        os.remove(cp)\n",
    "        print(f\"ðŸ—‘ï¸ Removed cache: {cp}\")\n",
    "\n",
    "print(\"Done. Now ensure labels_dir points to the correct phase before training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original classes from the downloaded dataset's labels.txt\n",
    "original_classes = {\n",
    "    0: 'sunglass', 1: 'hat', 2: 'jacket', 3: 'shirt', 4: 'pants',\n",
    "    5: 'shorts', 6: 'skirt', 7: 'dress', 8: 'bag', 9: 'shoe'\n",
    "}\n",
    "\n",
    "# PHASE 1: New coarse classes (TOP, BOTTOM, SHOES)\n",
    "phase1_classes = {'TOP': 0, 'BOTTOM': 1, 'SHOES': 2}\n",
    "# This maps the ORIGINAL class ID to the NEW Phase 1 class ID\n",
    "phase1_map = {\n",
    "    0: None,  # sunglass\n",
    "    1: None,  # hat\n",
    "    2: 0,     # jacket -> TOP\n",
    "    3: 0,     # shirt  -> TOP\n",
    "    4: 1,     # pants  -> BOTTOM\n",
    "    5: 1,     # shorts -> BOTTOM\n",
    "    6: 1,     # skirt  -> BOTTOM\n",
    "    7: 0,     # dress  -> TOP\n",
    "    8: None,  # bag\n",
    "    9: 2      # shoe   -> SHOES\n",
    "}\n",
    "\n",
    "# PHASE 2: Your new fine-grained classes (without sunglass, bag, hat)\n",
    "phase2_classes = {\n",
    "    'jacket': 0, 'shirt': 1, 'pants': 2, 'shorts': 3,\n",
    "    'skirt': 4, 'dress': 5, 'shoe': 6\n",
    "}\n",
    "# This maps the ORIGINAL class ID to the NEW Phase 2 class ID\n",
    "phase2_map = {\n",
    "    0: None,  # sunglass\n",
    "    1: None,  # hat\n",
    "    2: 0,     # jacket\n",
    "    3: 1,     # shirt\n",
    "    4: 2,     # pants\n",
    "    5: 3,     # shorts\n",
    "    6: 4,     # skirt\n",
    "    7: 5,     # dress\n",
    "    8: None,  # bag\n",
    "    9: 6      # shoe\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_phase1_dir = os.path.join(dataset_root, 'labels_phase1')\n",
    "labels_phase2_dir = os.path.join(dataset_root, 'labels_phase2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Create the new label directories ---\n",
    "# Clear any old directories first and create clean ones\n",
    "if os.path.exists(labels_phase1_dir): shutil.rmtree(labels_phase1_dir)\n",
    "os.makedirs(labels_phase1_dir)\n",
    "\n",
    "if os.path.exists(labels_phase2_dir): shutil.rmtree(labels_phase2_dir)\n",
    "os.makedirs(labels_phase2_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Process each original label file ---\n",
    "processed_files = 0\n",
    "for filename in os.listdir(original_annotations_path):\n",
    "    if not filename.endswith('.txt'):\n",
    "        continue\n",
    "\n",
    "    new_phase1_lines = []\n",
    "    new_phase2_lines = []\n",
    "\n",
    "    with open(os.path.join(original_annotations_path, filename), 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if not parts:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                original_class_id = int(parts[0])\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "            box_coords = ' '.join(parts[1:])\n",
    "\n",
    "            # --- Process for Phase 1 ---\n",
    "            if original_class_id in phase1_map:\n",
    "                new_class_id = phase1_map[original_class_id]\n",
    "                if new_class_id is not None:\n",
    "                    new_phase1_lines.append(f\"{new_class_id} {box_coords}\")\n",
    "\n",
    "            # --- Process for Phase 2 ---\n",
    "            if original_class_id in phase2_map:\n",
    "                new_class_id = phase2_map[original_class_id]\n",
    "                if new_class_id is not None:\n",
    "                    new_phase2_lines.append(f\"{new_class_id} {box_coords}\")\n",
    "\n",
    "    # Write the new, filtered label files for each phase (create empty file if nothing)\n",
    "    with open(os.path.join(labels_phase1_dir, filename), 'w') as f:\n",
    "        if new_phase1_lines:\n",
    "            f.write('\\n'.join(new_phase1_lines))\n",
    "\n",
    "    with open(os.path.join(labels_phase2_dir, filename), 'w') as f:\n",
    "        if new_phase2_lines:\n",
    "            f.write('\\n'.join(new_phase2_lines))\n",
    "\n",
    "    processed_files += 1\n",
    "\n",
    "print(f\"âœ… Automatically processed {processed_files} files.\")\n",
    "print(f\"-> Phase 1 labels are ready in: '{labels_phase1_dir}'\")\n",
    "print(f\"-> Phase 2 labels are ready in: '{labels_phase2_dir}'\")\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Device detection (CUDA preferred, then MPS on Apple silicon, else CPU)\n",
    "device = 'cuda' if torch.cuda.is_available() else ('mps' if getattr(torch.backends, 'mps', None) and torch.backends.mps.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# 2) Quick label-coverage check (counts non-empty label files for train/val lists)\n",
    "def check_label_coverage(list_txt, labels_dir):\n",
    "    imgs = []\n",
    "    with open(list_txt, 'r') as f:\n",
    "        imgs = [l.strip() for l in f if l.strip()]\n",
    "    non_empty = 0\n",
    "    missing = 0\n",
    "    for p in imgs:\n",
    "        base = os.path.splitext(os.path.basename(p))[0]\n",
    "        lf = os.path.join(labels_dir, base + '.txt')\n",
    "        if not os.path.exists(lf):\n",
    "            missing += 1\n",
    "        else:\n",
    "            if os.path.getsize(lf) > 0:\n",
    "                non_empty += 1\n",
    "    print(f\"{os.path.basename(list_txt)}: {len(imgs)} images, {non_empty} non-empty labels, {missing} missing labels\")\n",
    "\n",
    "labels_dir = os.path.join(dataset_root, 'labels')  # this is what YOLO expects\n",
    "check_label_coverage(train_list_txt, labels_dir)\n",
    "check_label_coverage(val_list_txt, labels_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 3) Train with GPU/MPS, caching and mixed precision + early stopping (lower patience)\n",
    "print(\"\\n--- ðŸš€ STARTING PHASE 1 TRAINING ---\")\n",
    "# ensure labels for phase1 are available at dataset_root/labels (you already rename earlier)\n",
    "move_dir_overwrite(labels_phase1_dir, labels_dir)\n",
    "\n",
    "model_p1 = YOLO('yolov8n.pt')\n",
    "model_p1.train(\n",
    "    data='phase1-data.yaml',\n",
    "    epochs=50,            # reduce if you want faster cycles\n",
    "    imgsz=512,            # smaller images = faster\n",
    "    batch=16,\n",
    "    workers=8,            # increase if you have CPU cores and fast I/O\n",
    "    device=device,        # use GPU/CUDA or MPS if available\n",
    "    cache=True,           # cache images for faster epochs (ram/disk)\n",
    "    half=(device != 'cpu'),# use fp16 on GPU/MPS where supported\n",
    "    patience=10,          # early stopping after 10 epochs without val improvement\n",
    "    name='yolov8_phase1_coarse',\n",
    "    exist_ok=True\n",
    ")\n",
    "print(\"--- âœ… PHASE 1 TRAINING COMPLETE ---\")\n",
    "# Put labels back\n",
    "move_dir_overwrite(labels_dir, labels_phase1_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before Phase 2 training\n",
    "\n",
    "move_dir_overwrite(labels_phase2_dir, labels_dir)\n",
    "\n",
    "print(\"\\n--- ðŸš€ STARTING PHASE 2 TRAINING ---\")\n",
    "with switch_labels(labels_phase2_dir, labels_dir):\n",
    "    model_p2 = YOLO('runs/detect/yolov8_phase1_coarse/weights/best.pt')\n",
    "    model_p2.train(\n",
    "        data='phase2-data.yaml',\n",
    "        epochs=50, imgsz=512, batch=16, workers=8,\n",
    "        device=device, cache=True, half=(device!='cpu'),\n",
    "        patience=10, name='yolov8_phase2_fine', exist_ok=True\n",
    "    )\n",
    "\n",
    "print(\"--- âœ… PHASE 2 TRAINING COMPLETE ---\")\n",
    "move_dir_overwrite(labels_dir, labels_phase2_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GitHub Copilot\n",
    "\n",
    "Cause\n",
    "Youâ€™re renaming a directory onto an existing non-empty directory. On macOS, os.rename canâ€™t overwrite a non-empty destination, and your cell calls rename twice (safe_rename + os.rename), making it more likely to fail.\n",
    "\n",
    "Quick fix in your notebook\n",
    "- Add this helper once.\n",
    "- Replace both os.rename(...) calls with move_dir_overwrite(...).\n",
    "- Remove the duplicate rename line.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add once in a notebook cell\n",
    "import os, shutil\n",
    "\n",
    "def move_dir_overwrite(src, dst):\n",
    "    if not os.path.exists(src):\n",
    "        print(f\"Skip move: missing {src}\")\n",
    "        return\n",
    "    if os.path.exists(dst):\n",
    "        # avoid rmtree if they are the same inode\n",
    "        try:\n",
    "            if os.path.samefile(src, dst):\n",
    "                return\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "        shutil.rmtree(dst)\n",
    "    shutil.move(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Use it around training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before Phase 1 training\n",
    "move_dir_overwrite(labels_phase1_dir, labels_dir)\n",
    "\n",
    "# ... train Phase 1 ...\n",
    "\n",
    "print(\"--- âœ… PHASE 1 TRAINING COMPLETE ---\")\n",
    "# Put labels back\n",
    "move_dir_overwrite(labels_dir, labels_phase1_dir)\n",
    "\n",
    "# Before Phase 2 training\n",
    "move_dir_overwrite(labels_phase2_dir, labels_dir)\n",
    "\n",
    "# ... train Phase 2 ...\n",
    "\n",
    "print(\"--- âœ… PHASE 2 TRAINING COMPLETE ---\")\n",
    "move_dir_overwrite(labels_dir, labels_phase2_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Cleaner alternative\n",
    "Use your existing context manager to avoid manual moves entirely:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, pathlib\n",
    "sys.path.append(str(pathlib.Path('..').resolve() / 'src'))\n",
    "from modeling.common import switch_labels\n",
    "\n",
    "print(\"\\n--- ðŸš€ STARTING PHASE 1 TRAINING ---\")\n",
    "with switch_labels(labels_phase1_dir, labels_dir):\n",
    "    model_p1 = YOLO('yolov8n.pt')\n",
    "    model_p1.train(\n",
    "        data='phase1-data.yaml',\n",
    "        epochs=50, imgsz=512, batch=16, workers=8,\n",
    "        device=device, cache=True, half=(device!='cpu'),\n",
    "        patience=10, name='yolov8_phase1_coarse', exist_ok=True\n",
    "    )\n",
    "print(\"--- âœ… PHASE 1 TRAINING COMPLETE ---\")\n",
    "\n",
    "print(\"\\n--- ðŸš€ STARTING PHASE 2 TRAINING ---\")\n",
    "with switch_labels(labels_phase2_dir, labels_dir):\n",
    "    model_p2 = YOLO('runs/detect/yolov8_phase1_coarse/weights/best.pt')\n",
    "    model_p2.train(\n",
    "        data='phase2-data.yaml',\n",
    "        epochs=50, imgsz=512, batch=16, workers=8,\n",
    "        device=device, cache=True, half=(device!='cpu'),\n",
    "        patience=10, name='yolov8_phase2_fine', exist_ok=True\n",
    "    )\n",
    "print(\"--- âœ… PHASE 2 TRAINING COMPLETE ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Note\n",
    "- Ensure thereâ€™s no second os.rename after the move_dir_overwrite or within the context-managed block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_rename(labels_dir, labels_phase1_dir)\n",
    "\n",
    "\n",
    "print(\"--- âœ… PHASE 1 TRAINING COMPLETE ---\")\n",
    "os.rename(labels_dir, labels_phase1_dir)\n",
    "\n",
    "# Phase 2 (transfer learning) - same flags; ensure phase2 labels are present\n",
    "print(\"\\n--- ðŸš€ STARTING PHASE 2 TRAINING ---\")\n",
    "os.rename(labels_phase2_dir, labels_dir) if os.path.exists(labels_phase2_dir) and not os.path.exists(labels_dir) else None\n",
    "\n",
    "model_p2 = YOLO('runs/detect/yolov8_phase1_coarse/weights/best.pt')\n",
    "model_p2.train(\n",
    "    data='phase2-data.yaml',\n",
    "    epochs=50,\n",
    "    imgsz=512,\n",
    "    batch=16,\n",
    "    workers=8,\n",
    "    device=device,\n",
    "    cache=True,\n",
    "    half=(device != 'cpu'),\n",
    "    patience=10,\n",
    "    name='yolov8_phase2_fine',\n",
    "    exist_ok=True\n",
    ")\n",
    "print(\"--- âœ… PHASE 2 TRAINING COMPLETE ---\")\n",
    "os.rename(labels_dir, labels_phase2_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- ðŸ•µï¸â€â™‚ï¸ RUNNING HIERARCHICAL PREDICTION ---\")\n",
    "\n",
    "# --- Load both trained models ---\n",
    "model_coarse = YOLO('runs/detect/yolov8_phase1_coarse/weights/best.pt')\n",
    "model_fine = YOLO('runs/detect/yolov8_phase2_fine/weights/best.pt')\n",
    "\n",
    "# --- Helper function for IoU ---\n",
    "def calculate_iou(box1, box2):\n",
    "    x1_inter = max(box1[0], box2[0])\n",
    "    y1_inter = max(box1[1], box2[1])\n",
    "    x2_inter = min(box1[2], box2[2])\n",
    "    y2_inter = min(box1[3], box2[3])\n",
    "    inter_area = max(0, x2_inter - x1_inter) * max(0, y2_inter - y1_inter)\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "# --- Select a random image to test ---\n",
    "test_image_name = random.choice(os.listdir(images_path))\n",
    "test_image_path = os.path.join(images_path, test_image_name)\n",
    "print(f\"-> Testing on image: {test_image_name}\")\n",
    "\n",
    "img = cv2.imread(test_image_path)\n",
    "results_coarse = model_coarse(img, verbose=False)[0]\n",
    "results_fine = model_fine(img, verbose=False)[0]\n",
    "IOU_THRESHOLD = 0.7\n",
    "\n",
    "for fine_box in results_fine.boxes:\n",
    "    fine_xyxy = fine_box.xyxy[0].cpu().numpy()\n",
    "    fine_class_name = model_fine.names[int(fine_box.cls)]\n",
    "    best_match_coarse_name = \"Unknown\"\n",
    "    max_iou = 0\n",
    "    \n",
    "    for coarse_box in results_coarse.boxes:\n",
    "        iou = calculate_iou(fine_xyxy, coarse_box.xyxy[0].cpu().numpy())\n",
    "        if iou > max_iou:\n",
    "            max_iou = iou\n",
    "            best_match_coarse_name = model_coarse.names[int(coarse_box.cls)]\n",
    "    \n",
    "    label = f\"{best_match_coarse_name}: {fine_class_name}\" if max_iou > IOU_THRESHOLD else fine_class_name\n",
    "        \n",
    "    x1, y1, x2, y2 = map(int, fine_xyxy)\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "# --- Display the final result ---\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Hierarchical Prediction Result\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://storage.googleapis.com/kaggle-colab-exported-notebooks/lfiathan/fashion-object-detection-yolov8.a6e234ab-f7a7-40f8-9140-5bad7f55cb2f.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20251014/auto/storage/goog4_request&X-Goog-Date=20251014T010236Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=3978c138a741d01d0d9ed852961b8b655b604d0061e474f0688ff9ba4a21bbf2eb04cd49d373d97b40e8d1d5cc269cefbdc1e051818e4726a59ba9fbb07c544ce192f3c7a4b555756e524957f2cc0198805c8b44c7f6a9b5c54192199cc1074efba5fc8b8c470dc074498dca988d0419eb1cce84de375021f691043534f631c948d0156dce3b96d33f555bb9568e03ff247c6ff832ef844af02aac28a30e77e896ce72c2fa8e6c3b17d54b557c33f5bcf7ef21c2e41c26e0d6086ba2d49bcb76413f30dcdb5eac6187fb630a42dcb66cef313fb0337b56a128eef59234f33993e247604ba4909524778aa3a065c3ee7d7cae764fcdffce11f59e55ac46a7e506",
     "timestamp": 1760407058663
    }
   ]
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1942455,
     "sourceId": 3200379,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30408,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
