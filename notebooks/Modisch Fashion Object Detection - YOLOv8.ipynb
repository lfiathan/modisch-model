{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1654,
     "status": "ok",
     "timestamp": 1760409026274,
     "user": {
      "displayName": "alif aditya",
      "userId": "09765680414298989716"
     },
     "user_tz": -420
    },
    "id": "kMi2042vPb_X",
    "outputId": "edcc49a4-d6bf-4af9-ee54-f7fa0b9d4c46"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import kaggle\n",
    "import yaml\n",
    "import pathlib\n",
    "import random\n",
    "import shutil\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "print('Data source import complete.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3gAXwA1GPb_Y"
   },
   "source": [
    "# YOLOv8\n",
    "YOLOv8 is the newest state-of-the-art YOLO model that can be used for object detection, image classification, and instance segmentation tasks.<br>\n",
    "YOLOv8 includes numerous architectural and developer experience changes and improvements over YOLOv5.<br>\n",
    "\n",
    "## Why Should I Use YOLOv8?\n",
    "* YOLOv8 has a high rate of accuracy measured by COCO and Roboflow 100.\n",
    "* YOLOv8 comes with a lot of developer-convenience features, from an easy-to-use CLI to a well-structured Python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_slug = 'nguyngiabol/colorful-fashion-dataset-for-object-detection'\n",
    "output_path = './dataset' # The folder where data will be stored\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    print(f\"Dataset not found. Downloading '{dataset_slug}' from Kaggle...\")\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    # The API command to download and unzip the files\n",
    "    kaggle.api.dataset_download_files(dataset_slug, path=output_path, unzip=True)\n",
    "    print(\"✅ Download and extraction complete.\")\n",
    "else:\n",
    "    print(f\"✅ Dataset already found at '{output_path}'. Skipping download.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define key paths for the rest of the script\n",
    "dataset_root = os.path.join(output_path, 'colorful_fashion_dataset_for_object_detection')\n",
    "images_path = os.path.join(dataset_root, 'JPEGImages')\n",
    "original_annotations_path = os.path.join(dataset_root, 'Annotations_txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original classes from the downloaded dataset's labels.txt\n",
    "original_classes = {\n",
    "    0: 'sunglass', 1: 'hat', 2: 'jacket', 3: 'shirt', 4: 'pants',\n",
    "    5: 'shorts', 6: 'skirt', 7: 'dress', 8: 'bag', 9: 'shoe'\n",
    "}\n",
    "\n",
    "# PHASE 1: New coarse classes (TOP, BOTTOM, SHOES)\n",
    "phase1_classes = {'TOP': 0, 'BOTTOM': 1, 'SHOES': 2}\n",
    "# This maps the ORIGINAL class ID to the NEW Phase 1 class ID\n",
    "phase1_map = {\n",
    "    0: None,  # sunglass\n",
    "    1: None,  # hat\n",
    "    2: 0,     # jacket -> TOP\n",
    "    3: 0,     # shirt  -> TOP\n",
    "    4: 1,     # pants  -> BOTTOM\n",
    "    5: 1,     # shorts -> BOTTOM\n",
    "    6: 1,     # skirt  -> BOTTOM\n",
    "    7: 0,     # dress  -> TOP\n",
    "    8: None,  # bag\n",
    "    9: 2      # shoe   -> SHOES\n",
    "}\n",
    "\n",
    "# PHASE 2: Your new fine-grained classes (without sunglass, bag, hat)\n",
    "phase2_classes = {\n",
    "    'jacket': 0, 'shirt': 1, 'pants': 2, 'shorts': 3,\n",
    "    'skirt': 4, 'dress': 5, 'shoe': 6\n",
    "}\n",
    "# This maps the ORIGINAL class ID to the NEW Phase 2 class ID\n",
    "phase2_map = {\n",
    "    0: None,  # sunglass\n",
    "    1: None,  # hat\n",
    "    2: 0,     # jacket\n",
    "    3: 1,     # shirt\n",
    "    4: 2,     # pants\n",
    "    5: 3,     # shorts\n",
    "    6: 4,     # skirt\n",
    "    7: 5,     # dress\n",
    "    8: None,  # bag\n",
    "    9: 6      # shoe\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_phase1_dir = os.path.join(dataset_root, 'labels_phase1')\n",
    "labels_phase2_dir = os.path.join(dataset_root, 'labels_phase2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Create the new label directories ---\n",
    "# Clear any old directories first and create clean ones\n",
    "if os.path.exists(labels_phase1_dir): shutil.rmtree(labels_phase1_dir)\n",
    "os.makedirs(labels_phase1_dir)\n",
    "\n",
    "if os.path.exists(labels_phase2_dir): shutil.rmtree(labels_phase2_dir)\n",
    "os.makedirs(labels_phase2_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Process each original label file ---\n",
    "processed_files = 0\n",
    "for filename in os.listdir(original_annotations_path):\n",
    "    if not filename.endswith('.txt'):\n",
    "        continue\n",
    "\n",
    "    new_phase1_lines = []\n",
    "    new_phase2_lines = []\n",
    "\n",
    "    with open(os.path.join(original_annotations_path, filename), 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if not parts:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                original_class_id = int(parts[0])\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "            box_coords = ' '.join(parts[1:])\n",
    "\n",
    "            # --- Process for Phase 1 ---\n",
    "            if original_class_id in phase1_map:\n",
    "                new_class_id = phase1_map[original_class_id]\n",
    "                if new_class_id is not None:\n",
    "                    new_phase1_lines.append(f\"{new_class_id} {box_coords}\")\n",
    "\n",
    "            # --- Process for Phase 2 ---\n",
    "            if original_class_id in phase2_map:\n",
    "                new_class_id = phase2_map[original_class_id]\n",
    "                if new_class_id is not None:\n",
    "                    new_phase2_lines.append(f\"{new_class_id} {box_coords}\")\n",
    "\n",
    "    # Write the new, filtered label files for each phase (create empty file if nothing)\n",
    "    with open(os.path.join(labels_phase1_dir, filename), 'w') as f:\n",
    "        if new_phase1_lines:\n",
    "            f.write('\\n'.join(new_phase1_lines))\n",
    "\n",
    "    with open(os.path.join(labels_phase2_dir, filename), 'w') as f:\n",
    "        if new_phase2_lines:\n",
    "            f.write('\\n'.join(new_phase2_lines))\n",
    "\n",
    "    processed_files += 1\n",
    "\n",
    "print(f\"✅ Automatically processed {processed_files} files.\")\n",
    "print(f\"-> Phase 1 labels are ready in: '{labels_phase1_dir}'\")\n",
    "print(f\"-> Phase 2 labels are ready in: '{labels_phase2_dir}'\")\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Create train/val image lists and YAML files for YOLOv8 ---\n",
    "def resolve_image_path(img_name, images_dir):\n",
    "    img_name = img_name.strip()\n",
    "    if not img_name:\n",
    "        return None\n",
    "    # if already has extension, check it directly\n",
    "    candidates = [img_name] if os.path.splitext(img_name)[1] else [img_name + ext for ext in ('.jpg', '.jpeg', '.png', '.png', '.JPG')]\n",
    "    for c in candidates:\n",
    "        p = os.path.join(images_dir, c)\n",
    "        if os.path.exists(p):\n",
    "            return os.path.abspath(p)\n",
    "    # try any file that startswith basename (some datasets have suffixes)\n",
    "    base = os.path.splitext(img_name)[0]\n",
    "    for f in os.listdir(images_dir):\n",
    "        if os.path.splitext(f)[0] == base:\n",
    "            return os.path.abspath(os.path.join(images_dir, f))\n",
    "    return None\n",
    "\n",
    "def make_list_from_imagesets(images_dir, list_relpath, out_txt):\n",
    "    list_path = os.path.join(dataset_root, list_relpath)\n",
    "    if not os.path.exists(list_path):\n",
    "        print(f\"⚠️  Missing file: {list_path}\")\n",
    "        open(out_txt, 'w').close()\n",
    "        return\n",
    "    lines = []\n",
    "    with open(list_path, 'r') as f:\n",
    "        for l in f:\n",
    "            p = resolve_image_path(l, images_dir)\n",
    "            if p:\n",
    "                lines.append(p)\n",
    "    if not lines:\n",
    "        print(f\"❗ No images resolved from {list_path}. Check filenames and extensions in {images_dir}.\")\n",
    "    with open(out_txt, 'w') as f:\n",
    "        f.write(\"\\n\".join(lines))\n",
    "    print(f\"✅ Wrote {out_txt} with {len(lines)} entries\")\n",
    "\n",
    "# image folder\n",
    "images_dir = images_path  # ./dataset/.../JPEGImages\n",
    "\n",
    "# create train/val txts with absolute image paths for Phase 1 / Phase 2 (they can reuse same lists)\n",
    "train_list_txt = os.path.abspath(os.path.join(dataset_root, 'train_full.txt'))\n",
    "val_list_txt   = os.path.abspath(os.path.join(dataset_root, 'val_full.txt'))\n",
    "\n",
    "# original ImageSets/Main files (VOC-style)\n",
    "make_list_from_imagesets(images_dir, 'ImageSets/Main/trainval.txt', train_list_txt)\n",
    "make_list_from_imagesets(images_dir, 'ImageSets/Main/test.txt', val_list_txt)\n",
    "\n",
    "# Helper to write yaml pointing to the list files\n",
    "def write_phase_yaml(path_root, train_txt, val_txt, names, out_fname):\n",
    "    cfg = {\n",
    "        'path': os.path.abspath(path_root),\n",
    "        'train': os.path.abspath(train_txt),\n",
    "        'val': os.path.abspath(val_txt),\n",
    "        'names': {i: n for i, n in enumerate(names)}\n",
    "    }\n",
    "    with open(out_fname, 'w') as f:\n",
    "        yaml.dump(cfg, f, sort_keys=False)\n",
    "    print(f\"✅ Wrote {out_fname}\")\n",
    "\n",
    "# Phase1 names list in index order\n",
    "phase1_names = [k for k,v in sorted(phase1_classes.items(), key=lambda kv: kv[1])]\n",
    "# Phase2 names list\n",
    "phase2_names = [k for k,v in sorted(phase2_classes.items(), key=lambda kv: kv[1])]\n",
    "\n",
    "write_phase_yaml(dataset_root, train_list_txt, val_list_txt, phase1_names, 'phase1-data.yaml')\n",
    "write_phase_yaml(dataset_root, train_list_txt, val_list_txt, phase2_names, 'phase2-data.yaml')\n",
    "print(\"✅ YAML configuration files created: 'phase1-data.yaml', 'phase2-data.yaml'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Device detection (CUDA preferred, then MPS on Apple silicon, else CPU)\n",
    "device = 'cuda' if torch.cuda.is_available() else ('mps' if getattr(torch.backends, 'mps', None) and torch.backends.mps.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# 2) Quick label-coverage check (counts non-empty label files for train/val lists)\n",
    "def check_label_coverage(list_txt, labels_dir):\n",
    "    imgs = []\n",
    "    with open(list_txt, 'r') as f:\n",
    "        imgs = [l.strip() for l in f if l.strip()]\n",
    "    non_empty = 0\n",
    "    missing = 0\n",
    "    for p in imgs:\n",
    "        base = os.path.splitext(os.path.basename(p))[0]\n",
    "        lf = os.path.join(labels_dir, base + '.txt')\n",
    "        if not os.path.exists(lf):\n",
    "            missing += 1\n",
    "        else:\n",
    "            if os.path.getsize(lf) > 0:\n",
    "                non_empty += 1\n",
    "    print(f\"{os.path.basename(list_txt)}: {len(imgs)} images, {non_empty} non-empty labels, {missing} missing labels\")\n",
    "\n",
    "labels_dir = os.path.join(dataset_root, 'labels')  # this is what YOLO expects\n",
    "check_label_coverage(train_list_txt, labels_dir)\n",
    "check_label_coverage(val_list_txt, labels_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 3) Train with GPU/MPS, caching and mixed precision + early stopping (lower patience)\n",
    "print(\"\\n--- 🚀 STARTING PHASE 1 TRAINING ---\")\n",
    "# ensure labels for phase1 are available at dataset_root/labels (you already rename earlier)\n",
    "os.rename(labels_phase1_dir, labels_dir) if os.path.exists(labels_phase1_dir) and not os.path.exists(labels_dir) else None\n",
    "\n",
    "model_p1 = YOLO('yolov8n.pt')\n",
    "model_p1.train(\n",
    "    data='phase1-data.yaml',\n",
    "    epochs=50,            # reduce if you want faster cycles\n",
    "    imgsz=512,            # smaller images = faster\n",
    "    batch=16,\n",
    "    workers=8,            # increase if you have CPU cores and fast I/O\n",
    "    device=device,        # use GPU/CUDA or MPS if available\n",
    "    cache=True,           # cache images for faster epochs (ram/disk)\n",
    "    half=(device != 'cpu'),# use fp16 on GPU/MPS where supported\n",
    "    patience=10,          # early stopping after 10 epochs without val improvement\n",
    "    name='yolov8_phase1_coarse',\n",
    "    exist_ok=True\n",
    ")\n",
    "print(\"--- ✅ PHASE 1 TRAINING COMPLETE ---\")\n",
    "os.rename(labels_dir, labels_phase1_dir)\n",
    "\n",
    "# Phase 2 (transfer learning) - same flags; ensure phase2 labels are present\n",
    "print(\"\\n--- 🚀 STARTING PHASE 2 TRAINING ---\")\n",
    "os.rename(labels_phase2_dir, labels_dir) if os.path.exists(labels_phase2_dir) and not os.path.exists(labels_dir) else None\n",
    "\n",
    "model_p2 = YOLO('runs/detect/yolov8_phase1_coarse/weights/best.pt')\n",
    "model_p2.train(\n",
    "    data='phase2-data.yaml',\n",
    "    epochs=50,\n",
    "    imgsz=512,\n",
    "    batch=16,\n",
    "    workers=8,\n",
    "    device=device,\n",
    "    cache=True,\n",
    "    half=(device != 'cpu'),\n",
    "    patience=10,\n",
    "    name='yolov8_phase2_fine',\n",
    "    exist_ok=True\n",
    ")\n",
    "print(\"--- ✅ PHASE 2 TRAINING COMPLETE ---\")\n",
    "os.rename(labels_dir, labels_phase2_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 🕵️‍♂️ RUNNING HIERARCHICAL PREDICTION ---\")\n",
    "\n",
    "# --- Load both trained models ---\n",
    "model_coarse = YOLO('runs/detect/yolov8_phase1_coarse/weights/best.pt')\n",
    "model_fine = YOLO('runs/detect/yolov8_phase2_fine/weights/best.pt')\n",
    "\n",
    "# --- Helper function for IoU ---\n",
    "def calculate_iou(box1, box2):\n",
    "    x1_inter = max(box1[0], box2[0])\n",
    "    y1_inter = max(box1[1], box2[1])\n",
    "    x2_inter = min(box1[2], box2[2])\n",
    "    y2_inter = min(box1[3], box2[3])\n",
    "    inter_area = max(0, x2_inter - x1_inter) * max(0, y2_inter - y1_inter)\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "# --- Select a random image to test ---\n",
    "test_image_name = random.choice(os.listdir(images_path))\n",
    "test_image_path = os.path.join(images_path, test_image_name)\n",
    "print(f\"-> Testing on image: {test_image_name}\")\n",
    "\n",
    "img = cv2.imread(test_image_path)\n",
    "results_coarse = model_coarse(img, verbose=False)[0]\n",
    "results_fine = model_fine(img, verbose=False)[0]\n",
    "IOU_THRESHOLD = 0.7\n",
    "\n",
    "for fine_box in results_fine.boxes:\n",
    "    fine_xyxy = fine_box.xyxy[0].cpu().numpy()\n",
    "    fine_class_name = model_fine.names[int(fine_box.cls)]\n",
    "    best_match_coarse_name = \"Unknown\"\n",
    "    max_iou = 0\n",
    "    \n",
    "    for coarse_box in results_coarse.boxes:\n",
    "        iou = calculate_iou(fine_xyxy, coarse_box.xyxy[0].cpu().numpy())\n",
    "        if iou > max_iou:\n",
    "            max_iou = iou\n",
    "            best_match_coarse_name = model_coarse.names[int(coarse_box.cls)]\n",
    "    \n",
    "    label = f\"{best_match_coarse_name}: {fine_class_name}\" if max_iou > IOU_THRESHOLD else fine_class_name\n",
    "        \n",
    "    x1, y1, x2, y2 = map(int, fine_xyxy)\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "# --- Display the final result ---\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Hierarchical Prediction Result\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://storage.googleapis.com/kaggle-colab-exported-notebooks/lfiathan/fashion-object-detection-yolov8.a6e234ab-f7a7-40f8-9140-5bad7f55cb2f.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20251014/auto/storage/goog4_request&X-Goog-Date=20251014T010236Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=3978c138a741d01d0d9ed852961b8b655b604d0061e474f0688ff9ba4a21bbf2eb04cd49d373d97b40e8d1d5cc269cefbdc1e051818e4726a59ba9fbb07c544ce192f3c7a4b555756e524957f2cc0198805c8b44c7f6a9b5c54192199cc1074efba5fc8b8c470dc074498dca988d0419eb1cce84de375021f691043534f631c948d0156dce3b96d33f555bb9568e03ff247c6ff832ef844af02aac28a30e77e896ce72c2fa8e6c3b17d54b557c33f5bcf7ef21c2e41c26e0d6086ba2d49bcb76413f30dcdb5eac6187fb630a42dcb66cef313fb0337b56a128eef59234f33993e247604ba4909524778aa3a065c3ee7d7cae764fcdffce11f59e55ac46a7e506",
     "timestamp": 1760407058663
    }
   ]
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 1942455,
     "sourceId": 3200379,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30408,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
